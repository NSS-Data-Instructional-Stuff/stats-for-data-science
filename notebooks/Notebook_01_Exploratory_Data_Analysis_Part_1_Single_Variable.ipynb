{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Variable Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, we'll be using the `pandas` and `numpy` libraries to perform some of your calculations and the `pyplot` module from `matplotlib`. \n",
    "\n",
    "A **library** bundles together functions and objects that have a common functionality (like data or statistical analysis).\n",
    "\n",
    "These must be imported in order to use them. \n",
    "\n",
    "We'll *alias* `pandas` as `pd` so that when we refer to it later, we'll only need to type `pd`. Similarly, we'll alias `numpy` and `matplotlib.pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools that we use depend on whether we're looking at numeric or categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative/Categorial Variables\n",
    "\n",
    "Recall that qualitative variables are those that fall into two or more levels/groups.\n",
    "\n",
    "The most interesting information in regard to qualitative variables is the number of observations per level/group.\n",
    "\n",
    "You can also look for the **mode** of a categorical variable, or the most frequent observation.\n",
    "\n",
    "This can be displayed in a **frequency table**, which shows a count of observations per category.\n",
    "\n",
    "For this example, we'll look at data from the 2018 Central Park Squirrel Census, which can be obtained from https://data.cityofnewyork.us/Environment/2018-Central-Park-Squirrel-Census-Squirrel-Data/vfnx-vebw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read the data into a pandas DataFrame so the we can manipulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels = pd.read_csv('../data/squirrels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break apart what happened in the previous cell.\n",
    "\n",
    "```\n",
    "squirrels = pd.read_csv('../data/squirrels.csv')\n",
    "```\n",
    "\n",
    "* `pd`: This refers to the pandas library (remember the alias from above). We are using a function from the pandas libary, so need to indicate this.\n",
    "\n",
    "* `.read_csv`: This is the name of the function we are using. Functions are used to perform differnt actions. In this case, we are reading the data from a csv file. Note that when you call a function, you'll have a set of parentheses on the end.\n",
    "\n",
    "* `'../data/squirrels.csv'`: This function needs to know where to look for the data, so we must supply it with a filepath to locate the csv file.\n",
    "\n",
    "* `squirrels =`: This assigns the result of the function call to a variable named squirrels so that we can refer to it and reuse it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the squirrels variable by calling it, like we do in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are seeing is a **DataFrame**, an object from the pandas library which is useful for working with tabular data.\n",
    "\n",
    "DataFrames are made up of **rows** and **columns**. Each row consists of an observation and we have a column for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the first few rows by using the `.head()` **method**. This is a function which is built in to DataFrames.\n",
    "\n",
    "To use a dataframe method, you normally type the name of the dataframe followed by a `.` and the name of the method you wish to use. \n",
    "\n",
    "Note also that when using methods, you need to put a set of parentheses after the name of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you notice when looking at the first few rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To see the list of all columns, you can take a look at the `columns` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the variables in the dataset is the primary fur color. We can access a single column from a data frame by using square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When extracting a single column like we did above, we get a pandas **Series**. A Series can basically be understood as a single column of a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see how many squirrels there were for each fur color, you can use the `value_counts` method from `pandas` to create a frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that gray squirrels are by far the most common squirrel spotted in Central Park in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `value_counts` will return a count of each category, but what if we want to modify the behavior of this function? This can be done by passing in some additional **arguments**. To get a list of available arguments and what they do, we can bring up the docstrings. \n",
    "\n",
    "For this function, we can bring up the docstring by referencing the function name, placing the cursor inside the parentheses and hitting Shift + Tab. If you do this 4 times, it'll pin the docstring to the bottom of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to check the documentation, which for `value_counts` is located at https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not interested in the *number* of observations of each group, but instead the *proportion* of observations in each category, you can add the `normalize = True` argument. This gives the **relative frequency** of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to visualize the frequency per color, you can create a **bar plot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few small improvements you can make:\n",
    "1. Add a semicolon to the last line, which suppresses the unneeded text output.\n",
    "2. Use the `.xticks()` function from matplotlib to remove the rotation for the labels.\n",
    "3. Use the `.title()` method to add a title to our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color'].value_counts().plot(kind = 'bar')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.title('Number of Squirrels by Each Primary Fur Color');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn \n",
    "\n",
    "**Question 1:** What percentage of the time were squirrels observed approaching (as indicated by the \"Approaches\" column)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Which age group (contained in the \"Age\" column) was most commonly spotted? Make a bar chart to show this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Are there any duplicate Unique Squirrel IDs? \n",
    "\n",
    "Bonus: How many are duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the DataFrame contains a lot of NaN values. If we want to be able to count these, we can utilize the `dropna` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels['Primary Fur Color'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want a general overview of the number of missing values per column, we can use the `isna` method followed by the `sum` method, or if we want the percentage of missing values, we can use `isna` in combination with `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrels.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative/Numerical Variables\n",
    "\n",
    "Numerical variables are those which can be counted or measured. There are number of ways we can examine numerical variables.\n",
    "\n",
    "Let's look at a new dataset, one which contains stats for all active NBA players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = pd.read_csv('../data/nba_players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which of the variables in this DataFrame are quantitative? Which are categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three major categories of descriptive statistics for quantitative variables:\n",
    "* Measures of Central Tendency\n",
    "* Measures of Variability/Spread\n",
    "* Measures of Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Central Tendency\n",
    "\n",
    "**Goal:** Give a central or \"typical\" value of a data set.\n",
    "\n",
    "Most common measures of central tendency:\n",
    "* mean\n",
    "* median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "Also known as the **average** or **arithmetic mean**. \n",
    "\n",
    "Defined as total (sum) of the values of a set of observations divided by the number of observations. \n",
    "\n",
    "The notation for the mean differs depending on if you are calculating it for a sample or for the entire population.\n",
    "\n",
    "$$\\text{Sample Mean: } \\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n} = \\frac{\\sum\\limits_{i=1}^n x_i}{n}$$\n",
    "\n",
    "$$\\text{Population Mean: } \\mu = \\frac{x_1 + x_2 + \\cdots + x_n}{n} = \\frac{\\sum\\limits_{i=1}^n x_i}{n}$$\n",
    "\n",
    "The mean represents the “balance point” of the data. It is the amount that all observations would have if the total amount of the variable was evenly distributed to all observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you'll manually calculate the mean, so that you can see how to use some of the methods available in `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].sum() / nba['salary'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` library has many of the common descriptive statistics available as methods. For example, to compute the mean salary, you didn't need to compute the sum and count, instead you could have taken advantage of the `mean` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that if you distributed the total payroll evenly to all players, they would each receive a salary of $8,900,391."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median\n",
    "\n",
    "The **median** is the number which divides the dataset exactly in half. It is the middle value if the data is arranged by size.\n",
    "\n",
    "For an odd number of observations, the median will be a value from the data set.\n",
    "\n",
    "For an even number of observations, the median is the mean of the two centermost observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that half of NBA players make less than \\\\$4,220,057 and half make more than \\\\$4,220,057. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Find the mean and median height in inches of nba players (which is contained in the `height_inches` column). What do you notice and how does it compare to what you saw with salaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we see such a vast difference between the mean and median for salaries but not for salaries? This may be caused by the fact that we have some very extreme values for the salary variable - players who make a lot more than the typical player. In fact, the salary values of the top earner is more than 11 times the median salary. These extreme values can have an outsized impact on the calculation of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.nlargest(5, 'salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, while there are very tall players, we do not have the same kind of extremes that we see with salary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.nlargest(5, 'height_inches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have seen is that the median is not as impacted by extreme values as the mean is. The term for this is that the median is **robust**. This is the reason that the median is often used to report statistics on salaries or home values, where extreme values are a common occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Shape\n",
    "\n",
    "So far, we've seen the center of our distributions using the mean and median, but what if we want to get a better idea about the overall distribution of values? When looking at a numerical variable, we can also inspect the *shape* of the distribution of that variable.\n",
    "\n",
    "The **distribution** refers to the possible values of that variable and which values occur more or less frequently than others.\n",
    "\n",
    "When talking about the shape of a distribution, there are a few different aspects we can examine:\n",
    "* **Symmetry:** Is the distribution symmetric? If so, is it \"bell-shaped\"? Is it flat?\n",
    "* **Skewness:** If it is not symmetic, does it have a long tail to one side?\n",
    "* **Peaks/Modes:** How many peaks does it have? Unimodal? Bimodal? Multimodal?\n",
    "* **Spread:** How narrow/wide is the distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "If you are trying to understand the shape of the distribution of a variable, the most common tool to use is the histrogram.\n",
    "\n",
    "A histogram shows how many observations lie within a certain class interval. That is, it divides the dataset into *bins*, and the height of the plot above each interval is proportional to the number of observations that fall within that bin.\n",
    "\n",
    "Procedure:\n",
    "* Separate data into equal-width, non-overlapping bins\n",
    "* Count number of data points in each bin\n",
    "* Draw a bar for each bin whose height is equal to the number of observations in that bin.\n",
    "\n",
    "Let's look at the weight_lbs variable and examine the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    data = nba,\n",
    "    x = 'weight_lbs'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a few improvements to our plot.\n",
    "\n",
    "**Note:** To see the possible _arguments_ for a function and a description of those arguments, you can press Shift + Tab inside the parentheses for that function to bring up the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6))               \n",
    "\n",
    "plt.hist(\n",
    "    data = nba,\n",
    "    x = 'weight_lbs',\n",
    "    edgecolor = 'black',\n",
    "    linewidth = 2\n",
    ");                              \n",
    "plt.xlabel('weight (lbs.)')                            \n",
    "plt.ylabel('count')\n",
    "plt.title('Histogram of NBA Player Weights');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** There is a bar in the middle whose height is about 100. What does this bar tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at our 4 questions:\n",
    "\n",
    "* **Symmetry:** Is the distribution symmetric? If so, is it \"bell-shaped\"? Is it flat?\n",
    "* **Skewness:** If it is not symmetic, does it have a long tail to one side?\n",
    "* **Peaks/Modes:** How many peaks does it have? Unimodal? Bimodal? Multimodal?\n",
    "* **Spread:** How narrow/wide is the distribution?\n",
    "\n",
    "While it is not a perfect mirror image from left to right, this distribution is mostly **symmetric** and not skewed. It is close to being bell-shaped.\n",
    "\n",
    "This distribution appears to be **unimodal**, with a large group of players whose weight is between about 215 and around 280 lbs. \n",
    "\n",
    "We can see that overall, the values are between about 160 and 300, with the distribution tailing off to either side.\n",
    "\n",
    "The way that matplotlib created the bins, it appears that maybe there is another mode around 240 lbs. Let's take a closer look at this.\n",
    "\n",
    "Histograms are very sensitive to how the bins are selected. If desired, we can supply our own bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(start = 160, stop = 320, step = 20)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6))               \n",
    "\n",
    "plt.hist(\n",
    "    data = nba,\n",
    "    x = 'weight_lbs',\n",
    "    edgecolor = 'black',\n",
    "    linewidth = 2,\n",
    "    bins = bins\n",
    ");                             \n",
    "plt.xlabel('weight (lbs.)')                            \n",
    "plt.ylabel('count')\n",
    "plt.title('Histogram of NBA Player Weights');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(start = 160, stop = 320, step = 10)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,6))               \n",
    "\n",
    "plt.hist(\n",
    "    data = nba,\n",
    "    x = 'weight_lbs',\n",
    "    edgecolor = 'black',\n",
    "    linewidth = 2,\n",
    "    bins = bins\n",
    ");                             \n",
    "plt.xlabel('weight (lbs.)')                            \n",
    "plt.ylabel('count')\n",
    "plt.title('Histogram of NBA Player Weights');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at our histogram in this view, we can see a little bit more about the symmetry of our data and see that it has a slight tail to the right, with some unusually high weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Create a histogram to examine the distribution of points per game (contained in the `pts_per_game` column). If you have time, also check on the `salary` column.\n",
    "\n",
    "Describe what you find in terms of the 4 questions:\n",
    "\n",
    "* **Symmetry:** Is the distribution symmetric? If so, is it \"bell-shaped\"? Is it flat?\n",
    "* **Skewness:** If it is not symmetic, does it have a long tail to one side?\n",
    "* **Peaks/Modes:** How many peaks does it have? Unimodal? Bimodal? Multimodal?\n",
    "* **Spread:** How narrow/wide is the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness\n",
    "\n",
    "When a dataset has a long tail to the right, you say that it is **right-skewed**. \n",
    "\n",
    "Analogously, a dataset with a long tail to the left (unusually small observations) would be said to be **left-skewed**.\n",
    "\n",
    "A long tail to one side will tend to pull the mean in that direction. The median is typically not affected as much by a long tail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of Modes\n",
    "\n",
    "Why do you need to care about how many modes a distribution has? When analyzing bimodal distribution, using the mean or even the median can be misleading. It can easily be the case that there are very few observations close to the mean or median. This can be a problem is you are interpreting these measures of central tendency as \"typical\" values. This can happen when the overall population is made up of two or more heterogeneous groups.\n",
    "\n",
    "See https://www.nalp.org/startingsalarydistributionclassof2009 for an example of a bimodal distribution where normal descriptive statistics are misleading. This website shows the distribution of starting salaries for lawyers in 2009. For lawyers, salaries are typically very high (for those that get full-time positions) or very low (for those that can only secure part-time employment). As a result, the salaries follow a bimodal distribution and almost no one makes the mean or median salary.\n",
    "\n",
    "<img src=\"images/2009_bimodal_in_color_for_web.gif\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Spread\n",
    "\n",
    "**Goal:** Give an idea of how similar or varied the observations in the dataset are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range\n",
    "\n",
    "The range measures how \"wide\" a dataset is. It depends only on the largest and smallest observations, so it is highly influenced by outliers.\n",
    "\n",
    "$$ \\text{range} = \\text{maximum observation} - \\text{minimum observation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know who has the largest salary, you can use the `nlargest` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.nlargest(1, 'weight_lbs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar for the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.nsmallest(1, 'weight_lbs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the range, you can subtract the minimum value from the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].max() - nba['weight_lbs'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range for heights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "nba['height_inches'].max() - nba['height_inches'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Standard Deviation\n",
    "\n",
    "The range of a dataset gives a quick glance at how varied a dataset is. It does have a major drawback, though, in that it only depends on two data points: the largest and smallest. What if you want to consider the entire dataset?\n",
    "\n",
    "Let's focus on the height variable. For each player, we'll consider their **deviation:** the difference between their height and the average height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['height_deviation'] = nba['height_inches'] - nba['height_inches'].mean()\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How do we interpret the value of 4.37961 for Steven Adams? What about the -1.62039 for Ochai Agbaji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the average deviation from the mean? Why do you think that you get this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one problem with simply taking the average of the deviations: if you were to sum the deviations, you would get zero, meaning that, on average, the deviation is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution for the problem that we just encountered is to, for each datapoint $x_i$, look at the squared deviation $(x_i - \\mu)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now take the mean of these squared deviations, you get what is called the **variance**. Note that this formula is only valid if you are looking at a *population*. You'll see the difference for a sample shortly.\n",
    "$$\\text{Population Variance: } \\sigma^2 = \\frac{\\sum\\limits_{i = 1}^n(x_i - \\mu)^2}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['squared_height_deviation'] = nba['height_deviation']**2\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['squared_height_deviation'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one problem now: the variance is is squared units, not in our original unit. If we want to convert it to the starting units, you can take the square root and obtain what is called the **standard deviation**:\n",
    "\n",
    "$$\\text{Population Standard Deviation: } \\sigma = \\sqrt{\\sigma^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(nba['squared_height_deviation'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with sample, there is a small modification that must be done to calculate the variance and standard deviation. Instead of dividing the $n$, the number of observations, you instead divide by $n-1$:\n",
    "\n",
    "$$\\text{Sample Variance: } s^2 = \\frac{\\sum\\limits_{i = 1}^n(x_i - \\bar{x})^2}{n - 1}$$\n",
    "\n",
    "$$\\text{Sample Standard Deviation: } s = \\sqrt{s^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the effect of this difference? (Is the sample variance larger or smaller than the population variance?)\n",
    "\n",
    "\n",
    "**Why do we have this difference?** \n",
    "\n",
    "Informally, the reason that you do this is that you are trying to approximate the population variance. You want to estimate the deviation from the mean, but at the same time, you don't know the true population mean to start with, only an estimate from the sample ($\\bar{x}$). So you are making an estimate using an estimate. To compensate for this, you need to inflate your estimate of the variance slightly, by dividing by $n - 1$ instead of $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, most function that calculate the variance or standard deviation will assume that you are looking at a sample. However, in this case, you have the entire population, so you need to adjust it. If you are using `pandas` methods, you can specify `ddof = 0`, which sets the \"delta degrees of freedom\", or the amount that the \"degrees of freedom\" differ from the number of observations, to be 0.\n",
    "\n",
    "If you are calculating the standard deviation of a sample, you need to use `ddof = 1` (which is the default behavior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['height_inches'].var(ddof = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['height_inches'].std(ddof = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the default behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['height_inches'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nssstats.plots import std_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "std_plot(nba['height_inches'], edgecolor = 'black', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For distributions that are approximately bell-shaped, about 2/3 of observations will be within one standard deviation of the mean.\n",
    "\n",
    "If, however, the distribution is non bell-shaped, this may not hold. For example, let's look at salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['salary'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "std_plot(nba['salary'], edgecolor = 'black', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens with this distribution? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $z$-scores\n",
    "\n",
    "\n",
    "\n",
    "Often, you are not as interested in understanding \"how much\", but instead \"how different from average?\". That is, you may wish to measure how \"unusual\" a particular observation is. \n",
    "\n",
    "A $z$-score allows you to answer this question, in terms of the number of standard deviations from the mean. It is *unitless*, which means that it does not depend on what is being measured and the scale of the measurements, but instead you can compare across different types of measurements.\n",
    "\n",
    "$$ z\\text{-score} = \\frac{\\text{observation} - \\text{mean}}{\\text{standard deviation}}$$\n",
    "\n",
    "A $z$-score of 1.4 says that an observation is 1.4 standard deviations larger than the average value, whereas a $z$-score of -2.8 says that an observation is 2.8 standard deviations lower than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['height_z-score'] = (nba['height_inches'] - nba['height_inches'].mean()) / nba['height_inches'].std(ddof = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the mean and standard deviation of the z-scores that were just calculated? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and calculate the z-scores for weight, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_z-score'] = (nba['weight_lbs'] - nba['weight_lbs'].mean()) / nba['weight_lbs'].std(ddof = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How do we interpret the z-scores for Zion Williamson? To see the values for Zion Williamson, we'll use the .loc property to filter down to his row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.loc[(nba['first_name'] == 'Zion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Position\n",
    "\n",
    "Measures of position have to do with ranking where an observation is in the dataset with respect to all other values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quartiles and Quantiles/Percentiles\n",
    "\n",
    "You have already encountered a special case of quantiles and percentiles, in the form of the median. Recall that the median of a dataset is the middle observation, if the observations are placed in ascending order. Another way to view this is that the median separates the lower half of the dataset from the upper half.\n",
    "\n",
    "Instead of dividing a dataset into halves, **quartiles** divide a dataset into quarters. \n",
    "\n",
    "The **first quartile** separates the smallest quarter of observations from the highest three-quarters, the **second quartile**, aka the median, separates the smallest half of observations from the largest half of observations, and the **third quartile** separates the smallest three-quarters from the largest quarter of observations.\n",
    "\n",
    "Quartiles (and more generally, **quantiles**) can be calculated using the `quantile` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that _pandas_ has a `describe` method which gives many of the summary statistics that we have mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the quantiles to find the **interquartile range**, which is defined as the distance from the first to the third quartile. In a way, it is a trimmed version of the range, which is not as sensitive to extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.75) - nba['weight_lbs'].quantile(q = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nssstats.plots import iqr_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "iqr_plot(nba['weight_lbs'], bins = 25, edgecolor = 'black', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, you can look at the quantiles or percentiles. The $n$th percentile separtes the lowest $n$% of observations from the rest. For example, the 90th percentile divides the lowest 90% of observations from the highest 10%. \n",
    "\n",
    "To find percentiles, you can use the quantile function from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba['weight_lbs'].quantile(q = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles can be used to identify unusual observations, or to trim outliers from a data set.\n",
    "\n",
    "If you want to understand how a variable is distributed, you have already seen how to use a histogram. An alternative type of plot that you can use is a **boxplot** (aka **box-and-whiskers plot**). This type of plot displays a box which starts at the first quartile and extend to the third quartile, with the second quartile marked. It also has whiskers that extend to last observations contained within the **outlier boundaries**. \n",
    "\n",
    "These boundaries are (usually) defined as being at 1.5 times the interquartile range below the first quartile and above the third quartile. Any points outside of the outiler boundaries are plotted individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "sns.boxplot(x = nba['weight_lbs']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "sns.boxplot(x = nba['salary']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add an argument to tell seaborn how to divide the data into categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.boxplot(data = nba.sort_values('team'), x = \"salary\", y = \"team\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What can we learn from this plot?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
