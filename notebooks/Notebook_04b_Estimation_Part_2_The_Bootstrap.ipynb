{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Confidence Intervals\n",
    "\n",
    "The **empirical bootstrap** is a technique popularized by Bradley Efron in 1979. It is easy to understand and implement, but is just recently gaining popularity, since it is not really feasible without modern computing power. The bootstrap allows us to substitute fast computation for theoretical math.\n",
    "\n",
    "**Big Idea:** perform computations on the data itself to estimate the variation of statistics that are themselves computed from the same data. That is, the data is ‘pulling itself up by its own bootstrap.’ \n",
    "\n",
    "Since the bootstrap allows you to estimate the variance of the sampling distribution of these statistics, you can use this technique to construct confidence intervals.\n",
    "\n",
    "Recall the procedure for building a 95% Bootstrap Conﬁdence Interval:\n",
    "\n",
    "1. Given a sample, ﬁnd the sample statistic $s$. This is the **point estimate**.\n",
    "2. Draw a large number (1,000 or so) resamples from the original sample and calculate the statistic $s^*$ for each.\n",
    "3. Find the 0.025 and 0.975 quantiles of the set of $s^* - s$. We'll call them $a$ and $b$,respectively.\n",
    "4. The 95% conﬁdence interval is given by $[s - b, s - a]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can create bootstap confidence intervals for different parameters.\n",
    "\n",
    "For this notebook, we'll be working with the Palmer penguins dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('../data/penguins.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Confidence Intervals for a Single Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look just at the adelie penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie = penguins[penguins['species'] == 'Adelie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a confidence interval for the mean body mass.\n",
    "\n",
    "The first thing to do is to find our point estimate, the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_estimate = adelie['body_mass_g'].mean()\n",
    "point_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set the number of resamples and the confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Resamples\n",
    "num_resamples = 1000\n",
    "\n",
    "#Confidence Level\n",
    "conf_level = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the confidence level, we can determine the cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = (1 - conf_level) / 2\n",
    "margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract out the sample values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = adelie['body_mass_g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resample these values, we can use the `choice` function from numpy's random module.\n",
    "\n",
    "This function takes in a 1-D array and will randomly sample from that array (with replacement by default). We can also use the `size` parameter in order to draw all of our resamples simulataneously. To use this parameter, we'll give it a tuple containing the number of resamples that we want and the size of the resamples (the same size as the original dataset).\n",
    "\n",
    "Here is an example use of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice([1,2,3], size = (5,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply it to our sample values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamples = np.random.choice(values, size = (num_resamples, values.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that this is the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an array where each row is a different resample. An advantage of creating the resamples in this way is that we can compute the mean values of all resamples simultaneously using the `mean` method. When doing this, we need to specify that we want to compute these using `axis = 1`, which indicates that we are computing the mean across the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resamples.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create out bootstrap samples, we need to compute the difference between the resample means and the point estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = resamples.mean(axis = 1) - point_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the quantiles of these differences to get the upper and lower bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's condense all of the code into one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_resamples = 10000\n",
    "conf_level = 0.95\n",
    "\n",
    "margin = (1 - conf_level) / 2\n",
    "\n",
    "values = adelie['body_mass_g']\n",
    "\n",
    "point_estimate = values.mean()\n",
    "\n",
    "resamples = np.random.choice(values, size = (num_resamples, values.count()))\n",
    "\n",
    "diffs = resamples.mean(axis = 1) - point_estimate\n",
    "\n",
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the $t$-interval, which we've seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.interval(alpha = 0.95, \n",
    "           df = values.count() - 1, \n",
    "           loc = values.mean(), \n",
    "           scale = sem(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One major advantage of the bootstrap is that we can use it for statistics even when we don't know the exact sampling distribution. For example, let's find the 95% bootstrap confidence interval for the median.\n",
    "\n",
    "Note that the median funtion is not built into numpy arrays, but we can use the `np.median` function and specify the axis for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_resamples = 10000\n",
    "conf_level = 0.95\n",
    "\n",
    "margin = (1 - conf_level) / 2\n",
    "\n",
    "values = adelie['flipper_length_mm']\n",
    "\n",
    "point_estimate = values.median()\n",
    "\n",
    "resamples = np.random.choice(values, size = (num_resamples, values.count()))\n",
    "\n",
    "diffs = np.median(resamples, axis = 1) - point_estimate\n",
    "\n",
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Modify the above code to find a 95% bootstrap confidence interval for the standard deviation of the flipper length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Confidence Interval for a Proportion\n",
    "\n",
    "Now, let's see how we can create bootstrap confidence interval for a proportion.\n",
    "\n",
    "For this, we'll work with a sample from the hotel booking demand dataset, which is described [here](https://www.sciencedirect.com/science/article/pii/S2352340918315191)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings = pd.read_csv('../data/bookings_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, let's estimate the proportion of reservations at city hotels that are canceled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quickly calculate a proportion, we can make use of the `mean` method of a numpy array. We can do this by checking that an observation is equal to a desired value and then using `mean` on the resulting array of Boolean values. (Note: in this case we do not have to check that the values are equal to 1 prior to using `mean`, but in cases where your variables are not encoded as 0/1, it would be necessary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what the observed frequency of bookings that are canceled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bookings['is_canceled'] == 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can largely reuse the code from above for our confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_resamples = 10000\n",
    "conf_level = 0.95\n",
    "\n",
    "margin = (1 - conf_level) / 2\n",
    "\n",
    "values = bookings['is_canceled']\n",
    "\n",
    "point_estimate = (values == 1).mean()\n",
    "\n",
    "resamples = np.random.choice(values, size = (num_resamples, values.count()))\n",
    "\n",
    "diffs = (resamples == 1).mean(axis = 1) - point_estimate\n",
    "\n",
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for a Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you may be interested in comparing the parameter value of two different groups. We can construct a confidence interval for the difference in parameters in a similar way as above, but we'll need to resample from each group.\n",
    "\n",
    "For example, let's say we want to build a confidence interval for the difference in the mean body mass between adelie and chinstrap penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(data = penguins, x = 'species', y = 'body_mass_g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinstrap = penguins[penguins['species'] == 'Chinstrap']\n",
    "\n",
    "chinstrap_values = chinstrap['body_mass_g']\n",
    "adelie_values = adelie['body_mass_g']\n",
    "\n",
    "num_resamples = 10000\n",
    "conf_level = 0.95\n",
    "\n",
    "margin = (1 - conf_level) / 2\n",
    "\n",
    "chinstrap_resamples = np.random.choice(chinstrap_values, size = (num_resamples, chinstrap_values.count()))\n",
    "adelie_resamples = np.random.choice(adelie_values, size = (num_resamples, adelie_values.count()))\n",
    "\n",
    "point_estimate = chinstrap_values.mean() - adelie_values.mean()\n",
    "\n",
    "diffs = chinstrap_resamples.mean(axis = 1) - adelie_resamples.mean(axis = 1) - point_estimate\n",
    "\n",
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that our confidence interval contains zero says that we can't immediately dismiss the possibility that adelie and chinstrap penguins have the same body mass on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval for Correlation\n",
    "\n",
    "Finally, let's see how we can construct a bootstrap confidence interval for a correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's remember how to find the correlation. Specifically, let's look at the correlation between flipper length and bill depth for adelie penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie.plot(kind = 'scatter', x = 'bill_depth_mm', y = 'flipper_length_mm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie[['flipper_length_mm', 'bill_depth_mm']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract just the correlation we care about, we can use the `iloc` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_estimate = adelie[['flipper_length_mm', 'bill_depth_mm']].corr().iloc[0, 1]\n",
    "point_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the `np.random.choice` function, we need a one-dimensional array. For this, we can use the index of the adelie DataFrame.\n",
    "\n",
    "Note that the index object does not have a `count` method, but we can use the `len` function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = adelie.index\n",
    "\n",
    "resamples = np.random.choice(values, size = (num_resamples, len(values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have now is a list of lists of index values for our resamples. Let's look at the procedure that we'll use to extract the correlation coefficient for each resample.\n",
    "\n",
    "For demonstration purposes, we'll look at the first resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = resamples[0]\n",
    "resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the corresponding rows, we can use the `.loc` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie.loc[resample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then filter and calculate the correlation for this resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie.loc[resample][['flipper_length_mm', 'bill_depth_mm']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what we really want is the difference between this correlation and the point estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelie.loc[resample][['flipper_length_mm', 'bill_depth_mm']].corr().iloc[0, 1] - point_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the procedure that we need to do for each resample, we can create a **for loop** to take each resample, extract the correlation and subtract our point estimate.\n",
    "\n",
    "We do need to store the result of each calculation, so we'll create a list and append the results to it as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "\n",
    "for resample in resamples:\n",
    "    diffs.append(adelie.loc[resample][['bill_length_mm', 'bill_depth_mm']].corr().iloc[0, 1] - point_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.quantile(diffs, q = margin)\n",
    "b = np.quantile(diffs, q = 1 - margin)\n",
    "\n",
    "print('lower bound: ', point_estimate - b)\n",
    "print('upper bound: ', point_estimate - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this result, we can say that, based on the data we have, there is at best a moderate correlation between flipper length and bill depth, and it might even be a very weak one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
